---
title: "illustration"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{illustration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# devtools::install()
library(vhdi)
```

## Method
We introduce three methods to generate the prediction intervals with robust coverage rate and shortest length. 

Let $\mathbf{X} = (X_1,\cdots,X_n)$ be an i.i.d random sample from a distribution with continuous cumulative distribution function $F$. For a given nominal error rate $\alpha$, a $100((1-\alpha)\%$ prediction interval for an independent future observation $X_{n+1}$ from the same distribution is a random interval $(L(\mathbf{X}), U(\mathbf{X}))$ such that

$$P(L(\mathbf{X})<X_{n+1}<U(\mathbf{X}))\geq 1-\alpha$$


We would like to use different methods to find $(L(\mathbf{X}), U(\mathbf{X}))$.


### Shortest prediction interval (with no correction)

Find the shortest intervals $(X_{(r)}, X_{(r+k)})$ such that $\frac{k}{n+1}  \geq \alpha$. $X_{(r)}$ is the $r$th order statistics of $X_1, \cdots, X_n$. Formally, $$r = \arg\min_{1\leq r \leq n-k}\{X_{(n+k)} - X_{(r)}\},$$
where $k = \lceil \alpha(n+1) \rceil$. This is the method implemented in \texttt{hdi} function from \texttt{bayestestR} package to find the highest density interval.

Or equivalently, we can search for $$\beta = \arg\min_{0\leq \beta\leq \alpha}\{X_{(r+k)} - X_{(r)}\},$$
where $r = \lfloor (n+1)\beta\rfloor$ and $r+k = \lceil (n+1)(1-\alpha+\beta)\rceil$.

If $r$(or $\beta$) is pre-specified or chosen at random, the above prediction interval $(X_{(r)}, X_{(r+k)})$ has coverage rate at least $1-\alpha$. However, the searching process introduces dependence to the data, and the selected shortest prediction interval will suffer from under-coverage problem.

### Conservative Prediction interval

The conservative prediction interval is obtained by choosing the shortest of the intervals $(X_{(r)}, X_{(n+k)})$ for $r = 1,\cdots ,n-k$, where $k = \lceil n(1-\alpha) + 1.12\sqrt{n\alpha}\rceil$. 

This method is proposed by Frey in 2013 paper "Data-driven nonparametric prediction intervals". The boost of nominal coverage rate is going to offset the under-coverage problem. This method is called conservative since it achieves the nominal coverage rate $1-\alpha$ in the worst case scenario, i.e.,

$$\text{inf}_{F\in\mathcal{F}}P(L(\mathbf{X})<X_{n+1}<U(\mathbf{X}))\geq 1-\alpha$$

where $\mathcal{F}$ is the set of distributions under consideration. Oftentimes, the interval obtained through this method is wider than necessary.

### Prediction interval using cross validation

The idea of boosting the nominal coverage rate from Frey(2013) is adopted. Instead of using coverage rate $1-\alpha +1.12\sqrt{\frac{\alpha}{n}}$, we will use cross validation to find the new coverage rate $1-\alpha + b$, where $b\in(0,\alpha)$ stands for "boost".

In k-fold cross-validation, the original sample is randomly partitioned into $k$ equal sized subsamples. Of the $k$ subsamples, a single subsample is retained as the validation data for testing the model, and the remaining $k-1$ subsamples are used as training data. Find the shortest prediction interval with a nominal coverage probability $1-\alpha+b$ using training data set and evaluate its empirical coverage rate on the testing data set. The chosen $b^*$ is the one having a more accurate coverage probability on the testing data set. Finally use all the data to find the shortest prediction interval with nominal coverage rate $1-\alpha+b^*$.

## Performance evaluated using simulated data

### Getting the prediction interval for one simulated data set

```{r}
# more details in ?get.interval
# Example: generate the samples from standard normal distribution
# use cross validation method to get the prediction interval using the generated sample
res = get.interval(METHOD = 3, DIST = "Normal", n = 1000)

# things needed for the plot below
lower_q = res$interval[1]
upper_q = res$interval[2]
data = res$data
# A histogram of the sample with a shaded area representing the range of the prediction interval
# inputs: sample data, lower bound of the prediction interval, upper bound of the prediction interval 
# output: a plot
h = hist(data, breaks=50, plot=FALSE)
cuts = cut(h$breaks, c(lower_q, upper_q))
plot(h$breaks, c(h$counts,0) ,type="s",col="black", lwd=2)
plot(h, col="gray"[cuts], lty="blank", add=T)
```

### Comparison of the coverage 

We conduct 100 experiments. For each experiment, we get the prediction interval using simulated data and get the coverage probability of the the prediction interval on the test data generated from the same distribution as the simulated data. The boxplot of 100 coverage probabilities is shown.

#### Prediction interval with random positions

In each experiment, we use a random chosen position. It's not going to be the shortest, but it's valid in coverage. This is to demonstrate as long as we do not introduce dependence, even a randomly chosen $\beta$ will give us valid coverage.

```{r}
n = 1000 ## training sample size
n0 = 1000 ## test sample size
alpha = 0.05 ## nominal error rate
n_exp = 100 # number of experiments
cov.box = vector(mode="double", length=n_exp)
for(i in 1:n_exp){
  beta = runif(1, min = 0, max = alpha)
  
  res = get.interval(METHOD = 1, DIST = "Normal", n = n, test_n = n0, beta = beta, test_data = T)
  x = res$data
  x0 = res$test_dataset
  lower_q = res$interval[1]
  upper_q = res$interval[2]
  
  coverage.x0 = 1-mean(lower_q<= x0 & upper_q >=x0)
  cov.box[i] = coverage.x0
}

boxplot(cov.box, main = paste(expression(alpha), '=', alpha, 'n=', n))
abline(h = alpha, col = 'red')
abline(h = mean(cov.box), col = 'blue')
```

#### Shortest prediction interval

With no correction on the nominal error rate, the prediction interval is going to undercover:

```{r}
n = 1000 ## training sample size
n0 = 1000 ## test sample size
alpha = 0.05 ## nominal error rate
n_exp = 100 # number of experiments
cov.box = vector(mode="double", length=n_exp)
for(i in 1:n_exp){
  res = get.interval(METHOD = 2, DIST = "Normal", n = n, test_n = n0, test_data = T)
  x = res$data
  x0 = res$test_dataset
  shortest_lower_q = res$interval[1]
  shortest_upper_q = res$interval[2]
  coverage.x0 = 1-mean(shortest_lower_q<= x0 & shortest_upper_q >=x0)
  cov.box[i] = coverage.x0
}

boxplot(cov.box, main = paste(expression(alpha), '=', alpha, 'n=', n))
abline(h = alpha, col = 'red')
abline(h = mean(cov.box), col = 'blue')
```


### Prediction interval using cross validation

```{r}
K = 2
n = 1000 ## training sample size
n0 = 1000 ## test sample size
alpha = 0.05 ## nominal error rate
n_exp = 100 # number of experiments
cov.box = vector(mode="double", length=n_exp)
for(i in 1:n_exp){
  res = get.interval(METHOD = 3, DIST = "Normal", n = n, test_n = n0, K=K, test_data = T)
  x = res$data
  x0 = res$test_dataset
  cv_lower_q = res$interval[1]
  cv_upper_q = res$interval[2]
  
  coverage.x0 = 1-mean(cv_lower_q<= x0 & cv_upper_q >=x0)
  cov.box[i] = coverage.x0
}

boxplot(cov.box, main = paste(expression(alpha), '=', alpha, 'n=', n))
abline(h = alpha, col = 'red')
abline(h = mean(cov.box), col = 'blue')
```



### Conservative Prediction interval

```{r}
n = 1000 ## training sample size
n0 = 1000 ## test sample size
alpha = 0.05 ## nominal error rate
n_exp = 100 # number of experiments
cov.box = vector(mode="double", length=n_exp)
for(i in 1:n_exp){
  res = get.interval(METHOD = 4, DIST = "Normal", n = n, test_n = n0, test_data = T)
  x = res$data
  x0 = res$test_dataset
  dv_lower_q = res$interval[1]
  dv_upper_q = res$interval[2]
  
  coverage.x0 = 1-mean(dv_lower_q<= x0 & dv_upper_q >=x0)
  cov.box[i] = coverage.x0
}

boxplot(cov.box, main = paste(expression(alpha), '=', alpha, 'n=', n))
abline(h = alpha, col = 'red')
abline(h = mean(cov.box), col = 'blue')
```


